# Store the current cycle length in the chain
cycle_chain[i] <- current_cycle
}
n_days
n_days <- length(daily_counts)
stl_poisson_predict <- function(cycle_length) {
# Decompose the series using STL with the given cycle length
ts_data <- ts(daily_counts, frequency = cycle_length)
stl_fit <- stl(ts_data, s.window = "periodic")
# Get trend and seasonal components
trend_component <- stl_fit$time.series[, "trend"]
seasonal_component <- stl_fit$time.series[, "seasonal"]
# Predicted Poisson rate (lambda) is based on the trend and seasonality
lambda_pred <- exp(trend_component + seasonal_component)
return(lambda_pred)
}
stl_poisson_predict(300)
log_posterior <- function(cycle_length) {
# Ensure cycle length is positive and within reasonable bounds
if (cycle_length <= 1 || cycle_length > n_days / 2) return(-Inf)
# Predicted Poisson rates from STL decomposition
lambda_hat <- stl_poisson_predict(cycle_length)
# Log-likelihood for Poisson counts
log_likelihood <- sum(dpois(daily_counts, lambda = lambda_hat, log = TRUE))
# Assume flat prior (no prior knowledge on cycle length)
log_prior <- 0
# Return the log-posterior (log-likelihood + log-prior)
return(log_likelihood + log_prior)
}
log_posterior(300)
log_posterior <- function(cycle_length) {
# Ensure cycle length is positive and within reasonable bounds
if (cycle_length <= 1 || cycle_length > n_days / 2) return(-Inf)
# Predicted Poisson rates from STL decomposition
lambda_hat <- stl_poisson_predict(cycle_length)
# Log-likelihood for Poisson counts
log_likelihood <- sum(dpois(daily_counts, lambda = lambda_hat, log = TRUE))
# Assume flat prior (no prior knowledge on cycle length)
log_prior <- 0
# Return the log-posterior (log-likelihood + log-prior)
return(log_likelihood + log_prior)
}
# MCMC Settings
num_iter <- 5000  # Number of iterations
burn_in <- 500    # Burn-in period
cycle_chain <- numeric(num_iter)  # To store the cycle length samples
# Initial cycle length (starting point for MCMC)
current_cycle <- 300
cycle_chain[1] <- current_cycle
# Proposal standard deviation (for proposing new cycle lengths)
proposal_sd <- 7
# Metropolis-Hastings algorithm for MCMC
for (i in 2:num_iter) {
# Propose new cycle length (add normal noise to current cycle length)
proposed_cycle <- current_cycle + rnorm(14, mean = 0, sd = proposal_sd)
# Log-posterior for current and proposed cycle lengths
log_posterior_current <- log_posterior(current_cycle)
log_posterior_proposed <- log_posterior(proposed_cycle)
# Acceptance probability (ratio of posteriors)
acceptance_prob <- exp(log_posterior_proposed - log_posterior_current)
# Accept or reject the proposal
if (runif(1) < acceptance_prob) {
current_cycle <- proposed_cycle
}
# Store the current cycle length in the chain
cycle_chain[i] <- current_cycle
}
# Propose new cycle length (add normal noise to current cycle length)
proposed_cycle <- current_cycle + rnorm(14, mean = 0, sd = proposal_sd)
# Log-posterior for current and proposed cycle lengths
log_posterior_current <- log_posterior(current_cycle)
log_posterior_proposed <- log_posterior(proposed_cycle)
proposed_cycle
proposed_cycle
cycle_length <- 296.9951
# Ensure cycle length is positive and within reasonable bounds
if (cycle_length <= 1 || cycle_length > n_days / 2) return(-Inf)
# Predicted Poisson rates from STL decomposition
lambda_hat <- stl_poisson_predict(cycle_length)
# Log-likelihood for Poisson counts
log_likelihood <- sum(dpois(daily_counts, lambda = lambda_hat, log = TRUE))
# Propose new cycle length (add normal noise to current cycle length)
proposed_cycle <- current_cycle + rnorm(14, mean = 0, sd = proposal_sd)
# Log-posterior for current and proposed cycle lengths
log_posterior_current <- log_posterior(current_cycle)
log_posterior_proposed <- log_posterior(proposed_cycle)
proposed_cycle
current_cycle
# MCMC Settings
num_iter <- 5000  # Number of iterations
burn_in <- 500    # Burn-in period
cycle_chain <- numeric(num_iter)  # To store the cycle length samples
# Initial cycle length (starting point for MCMC)
current_cycle <- 300
cycle_chain[1] <- current_cycle
# Proposal standard deviation (for proposing new cycle lengths)
proposal_sd <- 7
# Metropolis-Hastings algorithm for MCMC
for (i in 2:num_iter) {
# Propose new cycle length (add normal noise to current cycle length)
proposed_cycle <- current_cycle + rnorm(1, mean = 0, sd = proposal_sd)
# Log-posterior for current and proposed cycle lengths
log_posterior_current <- log_posterior(current_cycle)
log_posterior_proposed <- log_posterior(proposed_cycle)
# Acceptance probability (ratio of posteriors)
acceptance_prob <- exp(log_posterior_proposed - log_posterior_current)
# Accept or reject the proposal
if (runif(1) < acceptance_prob) {
current_cycle <- proposed_cycle
}
# Store the current cycle length in the chain
cycle_chain[i] <- current_cycle
}
# Remove burn-in period
cycle_chain <- cycle_chain[-(1:burn_in)]
# Plot trace of the cycle length
plot(cycle_chain, type = "l", col = "blue", main = "Trace Plot for Cycle Length",
ylab = "Cycle Length", xlab = "Iteration")
# Initial cycle length (starting point for MCMC)
current_cycle <- 365
cycle_chain[1] <- current_cycle
# Posterior summary of the cycle length
posterior_mean_cycle <- mean(cycle_chain)
posterior_cred_int <- quantile(cycle_chain, probs = c(0.025, 0.975))
cat("Posterior mean for cycle length:", posterior_mean_cycle, "\n")
cat("95% credible interval for cycle length:", posterior_cred_int, "\n")
num_iter <- 5000  # Number of iterations
burn_in <- 500    # Burn-in period
cycle_chain <- numeric(num_iter)  # To store the cycle length samples
# Initial cycle length (starting point for MCMC)
current_cycle <- 365
cycle_chain[1] <- current_cycle
# Proposal standard deviation (for proposing new cycle lengths)
proposal_sd <- 14
# Metropolis-Hastings algorithm for MCMC
for (i in 2:num_iter) {
# Propose new cycle length (add normal noise to current cycle length)
proposed_cycle <- current_cycle + rnorm(1, mean = 0, sd = proposal_sd)
# Log-posterior for current and proposed cycle lengths
log_posterior_current <- log_posterior(current_cycle)
log_posterior_proposed <- log_posterior(proposed_cycle)
# Acceptance probability (ratio of posteriors)
acceptance_prob <- exp(log_posterior_proposed - log_posterior_current)
# Accept or reject the proposal
if (runif(1) < acceptance_prob) {
current_cycle <- proposed_cycle
}
# Store the current cycle length in the chain
cycle_chain[i] <- current_cycle
}
# Remove burn-in period
cycle_chain <- cycle_chain[-(1:burn_in)]
# Plot trace of the cycle length
plot(cycle_chain, type = "l", col = "blue", main = "Trace Plot for Cycle Length",
ylab = "Cycle Length", xlab = "Iteration")
# Posterior summary of the cycle length
posterior_mean_cycle <- mean(cycle_chain)
posterior_cred_int <- quantile(cycle_chain, probs = c(0.025, 0.975))
cat("Posterior mean for cycle length:", posterior_mean_cycle, "\n")
cat("95% credible interval for cycle length:", posterior_cred_int, "\n")
hist(cycle_chain)
rnorm(1, mean = 0, sd = proposal_sd)
proposed_cycle
log_posterior_proposed - log_posterior_current
acceptance_prob
exp(log_posterior_proposed - log_posterior_current)
log_posterior_current
log_posterior_proposed
log_posterior_proposed - log_posterior_current
exp(log_posterior_proposed - log_posterior_current)
current_cycle
log_posterior
log_posterior(current_cycle)
log_posterior(300)
log_posterior(254)
log_posterior(365)
stl_poisson_predict(cycle_length)
daily_counts
# Decompose the series using STL with the given cycle length
ts_data <- ts(daily_counts, frequency = cycle_length)
stl_fit <- stl(ts_data, s.window = "periodic")
plot(stl_fit)
rpois(1, 13)
lambda_hat
rpois(1,1.168388e+12, log = T)
rpois(13,1.168388e+12, log = T)
dpois(13,1.168388e+12, log = T)
dpois(exp(13),1.168388e+12, log = T)
# Load necessary libraries
library(stats)
library(forecast)
# Simulate some daily count data with seasonality
set.seed(123)
n_days <- 365  # One year of daily data
seasonal_cycle <- 7  # Assume a weekly seasonality (7-day cycle)
trend <- 1:n_days / 100  # Slow trend over time
seasonal_component <- sin(2 * pi * (1:n_days) / seasonal_cycle) * 5  # Seasonal effect
lambda <- exp(trend + seasonal_component)  # Poisson rate
daily_counts <- rpois(n_days, lambda)
# Plot the simulated data
plot(daily_counts, type = "l", col = "blue", xlab = "Day", ylab = "Daily Count",
main = "Simulated Daily Count Data with Trend and Seasonality")
# Decompose the series using STL with the given cycle length
ts_data <- ts(daily_counts, frequency = cycle_length)
stl_fit <- stl(ts_data, s.window = "periodic")
# Get trend and seasonal components
trend_component <- stl_fit$time.series[, "trend"]
seasonal_component <- stl_fit$time.series[, "seasonal"]
# Predicted Poisson rate (lambda) is based on the trend and seasonality
lambda_pred <- exp(trend_component + seasonal_component)
lambda_pred
daily_counts
plot(lambda_pred)
plot(daily_counts)
# Plot the simulated data
plot(daily_counts, type = "l", col = "blue", xlab = "Day", ylab = "Daily Count",
main = "Simulated Daily Count Data with Trend and Seasonality")
# Predicted Poisson rate (lambda) is based on the trend and seasonality
lambda_pred <- exp(trend_component + seasonal_component)
plot(trend_component + seasonal_component)
plot(stl_fit)
length(trend_component)
# Simulate some daily count data with seasonality
set.seed(123)
n_days <- 365  # One year of daily data
seasonal_cycle <- 7  # Assume a weekly seasonality (7-day cycle)
trend <- 1:n_days / 100  # Slow trend over time
seasonal_component <- sin(2 * pi * (1:n_days) / seasonal_cycle) * 5  # Seasonal effect
lambda <- exp(trend + seasonal_component)  # Poisson rate
daily_counts <- rpois(n_days, lambda)
daily_counts
length(daily_counts)
# Plot the simulated data
plot(daily_counts, type = "l", col = "blue", xlab = "Day", ylab = "Daily Count",
main = "Simulated Daily Count Data with Trend and Seasonality")
# Decompose the series using STL with the given cycle length
ts_data <- ts(daily_counts, frequency = cycle_length)
stl_fit <- stl(ts_data, s.window = "periodic")
cycle_length <- 7
# Decompose the series using STL with the given cycle length
ts_data <- ts(daily_counts, frequency = cycle_length)
stl_fit <- stl(ts_data, s.window = "periodic")
# Get trend and seasonal components
trend_component <- stl_fit$time.series[, "trend"]
seasonal_component <- stl_fit$time.series[, "seasonal"]
# Predicted Poisson rate (lambda) is based on the trend and seasonality
lambda_pred <- exp(trend_component + seasonal_component)
plot(lambda_pred)
lambda_pred
# Decompose the series using STL with the given cycle length
ts_data <- ts(daily_counts, frequency = cycle_length)
stl_fit <- stl(ts_data, s.window = "periodic")
plot(stl_fit)
# Get trend and seasonal components
trend_component <- stl_fit$time.series[, "trend"]
seasonal_component <- stl_fit$time.series[, "seasonal"]
plot(trend_component + seasonal_component)
exp(500)
# Predicted Poisson rate (lambda) is based on the trend and seasonality
lambda_pred <- exp(trend_component + seasonal_component)
lambda_pred
# Function to perform STL decomposition and return the predicted counts based on the trend and seasonality
stl_poisson_predict <- function(cycle_length) {
# Decompose the series using STL with the given cycle length
ts_data <- ts(daily_counts, frequency = cycle_length)
stl_fit <- stl(ts_data, s.window = "periodic")
# Get trend and seasonal components
trend_component <- stl_fit$time.series[, "trend"]
seasonal_component <- stl_fit$time.series[, "seasonal"]
# Predicted Poisson rate (lambda) is based on the trend and seasonality
lambda_pred <- exp(trend_component + seasonal_component)
return(lambda_pred)
}
# Ensure cycle length is positive and within reasonable bounds
if (cycle_length <= 1 || cycle_length > n_days / 2) return(-Inf)
# Predicted Poisson rates from STL decomposition
lambda_hat <- stl_poisson_predict(cycle_length)
lambda_hat
# Log-likelihood for Poisson counts
log_likelihood <- sum(dpois(daily_counts, lambda = lambda_hat, log = TRUE))
log_likelihood
sum(dpois(daily_counts, lambda = lambda_hat, log = TRUE))
# Load necessary libraries
library(stats)
library(forecast)
# Simulate some daily count data with seasonality
set.seed(123)
n_days <- 365  # One year of daily data
seasonal_cycle <- 7  # Assume a weekly seasonality (7-day cycle)
trend <- 1:n_days / 100  # Slow trend over time
seasonal_component <- sin(2 * pi * (1:n_days) / seasonal_cycle) * 5  # Seasonal effect
lambda <- exp(trend + seasonal_component)  # Poisson rate
daily_counts <- rpois(n_days, lambda)
# Plot the simulated data
plot(daily_counts, type = "l", col = "blue", xlab = "Day", ylab = "Daily Count",
main = "Simulated Daily Count Data with Trend and Seasonality")
# Function to perform STL decomposition and return the predicted counts based on the trend and seasonality
stl_poisson_predict <- function(cycle_length) {
# Decompose the series using STL with the given cycle length
ts_data <- ts(daily_counts, frequency = cycle_length)
stl_fit <- stl(ts_data, s.window = "periodic")
# Get trend and seasonal components
trend_component <- stl_fit$time.series[, "trend"]
seasonal_component <- stl_fit$time.series[, "seasonal"]
# Predicted Poisson rate (lambda) is based on the trend and seasonality
lambda_pred <- exp(trend_component + seasonal_component)
return(lambda_pred)
}
# Define the log-posterior function for Poisson regression
log_posterior <- function(cycle_length) {
# Ensure cycle length is positive and within reasonable bounds
if (cycle_length <= 1 || cycle_length > n_days / 2) return(-Inf)
# Predicted Poisson rates from STL decomposition
lambda_hat <- stl_poisson_predict(cycle_length)
# Log-likelihood for Poisson counts
log_likelihood <- sum(dpois(daily_counts, lambda = lambda_hat, log = TRUE))
# Assume flat prior (no prior knowledge on cycle length)
log_prior <- 0
# Return the log-posterior (log-likelihood + log-prior)
return(log_likelihood + log_prior)
}
# MCMC Settings
num_iter <- 5000  # Number of iterations
burn_in <- 500    # Burn-in period
cycle_chain <- numeric(num_iter)  # To store the cycle length samples
# Initial cycle length (starting point for MCMC)
current_cycle <- 7
cycle_chain[1] <- current_cycle
# Proposal standard deviation (for proposing new cycle lengths)
proposal_sd <- 1
# Metropolis-Hastings algorithm for MCMC
for (i in 2:num_iter) {
# Propose new cycle length (add normal noise to current cycle length)
proposed_cycle <- current_cycle + rnorm(1, mean = 0, sd = proposal_sd)
# Log-posterior for current and proposed cycle lengths
log_posterior_current <- log_posterior(current_cycle)
log_posterior_proposed <- log_posterior(proposed_cycle)
# Acceptance probability (ratio of posteriors)
acceptance_prob <- exp(log_posterior_proposed - log_posterior_current)
# Accept or reject the proposal
if (runif(1) < acceptance_prob) {
current_cycle <- proposed_cycle
}
# Store the current cycle length in the chain
cycle_chain[i] <- current_cycle
}
# Load necessary libraries
library(stats)
library(ggplot2)
# Simulate some daily count data
set.seed(123)
n_days <- 300
days <- 1:n_days
lambda <- exp(0.05 * days)  # Exponential growth
daily_counts <- rpois(n_days, lambda)
# Function to calculate log-likelihood for Poisson regression
log_likelihood <- function(params, x, y) {
alpha <- params[1]  # Intercept
beta <- params[2]   # Slope
# Calculate the predicted lambda using the log link function
lambda_hat <- exp(alpha + beta * x)
# Calculate the log-likelihood
ll <- sum(dpois(y, lambda = lambda_hat, log = TRUE))
# Return negative log-likelihood (to minimize)
return(-ll)
}
# Function to evaluate different cycle lengths
evaluate_cycle_length <- function(cycle_length, x, y) {
# Decompose the series using STL
stl_decomp <- stl(ts(y, frequency = cycle_length), s.window = "periodic")
# Extract seasonal component (if needed)
seasonal_component <- stl_decomp$time.series[, "seasonal"]
# Use the detrended series for fitting
detrended_counts <- y - seasonal_component
# Fit the Poisson regression model using MLE
init_params <- c(0, 0)  # Initial guess for alpha and beta
fit <- optim(init_params, log_likelihood, x = x, y = detrended_counts,
method = "BFGS", control = list(fnscale = -1))
# Return the log-likelihood value
return(-fit$value)  # Return positive log-likelihood for comparison
}
# Search for the best cycle length
cycle_lengths <- seq(5, 30)  # Define range for cycle lengths
results <- sapply(cycle_lengths, evaluate_cycle_length, x = days, y = daily_counts)
# Load necessary libraries
library(stats)
library(ggplot2)
# Simulate some daily count data
set.seed(123)
n_days <- 300
days <- 1:n_days
lambda <- exp(0.05 * days)  # Exponential growth
# Load necessary libraries
library(stats)
library(ggplot2)
# Simulate some daily count data
set.seed(123)
n_days <- 300
days <- 1:n_days
lambda <- exp(0.05 * days)  # Exponential growth
daily_counts <- rpois(n_days, lambda)
# Function to calculate log-likelihood for Poisson regression
log_likelihood <- function(params, x, y) {
alpha <- params[1]  # Intercept
beta <- params[2]   # Slope
# Calculate the predicted lambda using the log link function
lambda_hat <- exp(alpha + beta * x)
# Calculate the log-likelihood
ll <- sum(dpois(y, lambda = lambda_hat, log = TRUE))
# Return negative log-likelihood (to minimize)
return(-ll)
}
# Function to evaluate different cycle lengths
evaluate_cycle_length <- function(cycle_length, x, y) {
# Decompose the series using STL
stl_decomp <- stl(ts(y, frequency = cycle_length), s.window = "periodic")
# Extract seasonal component (if needed)
seasonal_component <- stl_decomp$time.series[, "seasonal"]
# Use the detrended series for fitting
detrended_counts <- y - seasonal_component
# Fit the Poisson regression model using MLE
init_params <- c(0, 0)  # Initial guess for alpha and beta
fit <- optim(init_params, log_likelihood, x = x, y = detrended_counts,
method = "BFGS", control = list(fnscale = -1))
# Return the log-likelihood value
return(-fit$value)  # Return positive log-likelihood for comparison
}
# Search for the best cycle length
cycle_lengths <- seq(5, 30)  # Define range for cycle lengths
results <- sapply(cycle_lengths, evaluate_cycle_length, x = days, y = daily_counts)
# Load necessary libraries
library(stats)
library(ggplot2)
# Simulate some daily count data
set.seed(123)
n_days <- 300
days <- 1:n_days
lambda <- exp(0.05 * days)  # Exponential growth
daily_counts <- rpois(n_days, lambda)
# Function to calculate log-likelihood for Poisson regression
log_likelihood <- function(params, x, y) {
alpha <- params[1]  # Intercept
beta <- params[2]   # Slope
# Calculate the predicted lambda using the log link function
lambda_hat <- exp(alpha + beta * x)
# Calculate the log-likelihood
ll <- sum(dpois(y, lambda = lambda_hat, log = TRUE))
# Return negative log-likelihood (to minimize)
return(-ll)
}
# Function to evalu
# Load necessary libraries
library(stats)
library(ggplot2)
# Simulate some daily count data
set.seed(123)
n_days <- 300
days <- 1:n_days
lambda <- exp(0.05 * days)  # Exponential growth
daily_counts <- rpois(n_days, lambda)
# Function to calculate log-likelihood for Poisson regression
log_likelihood <- function(params, x, y) {
alpha <- params[1]  # Intercept
beta <- params[2]   # Slope
# Calculate the predicted lambda using the log link function
lambda_hat <- exp(alpha + beta * x)
# Calculate the log-likelihood
ll <- sum(dpois(y, lambda = lambda_hat, log = TRUE))
# Return negative log-likelihood (to minimize)
return(-ll)
}
# Function to evaluate different cycle lengths
evaluate_cycle_length <- function(cycle_length, x, y) {
# Decompose the series using STL
stl_decomp <- stl(ts(y, frequency = cycle_length), s.window = "periodic")
# Extract seasonal component (if needed)
seasonal_component <- stl_decomp$time.series[, "seasonal"]
# Use the detrended series for fitting
detrended_counts <- y - seasonal_component
# Fit the Poisson regression model using MLE
init_params <- c(0, 0)  # Initial guess for alpha and beta
fit <- optim(init_params, log_likelihood, x = x, y = detrended_counts,
method = "BFGS", control = list(fnscale = -1))
# Return the log-likelihood value
return(-fit$value)  # Return positive log-likelihood for comparison
}
# Search for the best cycle length
cycle_lengths <- seq(5, 30)  # Define range for cycle lengths
results <- sapply(cycle_lengths, evaluate_cycle_length, x = days, y = daily_counts)
plot(daily_counts)
# Load necessary libraries
library(stats)
library(ggplot2)
# Simulate some daily count data
set.seed(123)
n_days <- 300
days <- 1:n_days
lambda <- exp(0.05 * days)  # Exponential growth
daily_counts <- rpois(n_days, lambda)
# Function to calculate log-likelihood for Poisson regression
log_likelihood <- function(params, x, y) {
alpha <- params[1]  # Intercept
beta <- params[2]   # Slope
# Calculate the predicted lambda using the log link function
lambda_hat <- exp(alpha + beta * x)
# Calculate the log-likelihood
ll <- sum(dpois(y, lambda = lambda_hat, log = TRUE))
# Return negative log-likelihood (to minimize)
return(-ll)
}
log_likelihood(c(1,1), x, x)
log_likelihood(c(1,1), days, x)
